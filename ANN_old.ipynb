{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Options Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preprocessing\n",
    "2. Defining ANN Architecture\n",
    "3. Choosing activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables must be dropped, others must be repurposed. \n",
    "\n",
    "All columns are scaled using standardisation sklearn standard scaler, categorical variables are one hot encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/SPX/UnderlyingOptionsIntervals_3600sec_calcs_oi_2024-07-26.csv')\n",
    "df2 = pd.read_csv('data/SPX/UnderlyingOptionsIntervals_3600sec_calcs_oi_2024-08-30.csv')\n",
    "df3 = pd.read_csv('data/SPX/UnderlyingOptionsIntervals_3600sec_calcs_oi_2024-09-27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values:\n",
      "underlying_symbol           0\n",
      "quote_datetime              0\n",
      "root                        0\n",
      "expiration                  0\n",
      "strike                      0\n",
      "option_type                 0\n",
      "open                        0\n",
      "high                        0\n",
      "low                         0\n",
      "close                       0\n",
      "trade_volume                0\n",
      "bid_size                    0\n",
      "bid                         0\n",
      "ask_size                    0\n",
      "ask                         0\n",
      "underlying_bid              0\n",
      "underlying_ask              0\n",
      "implied_underlying_price    0\n",
      "active_underlying_price     0\n",
      "implied_volatility          0\n",
      "delta                       0\n",
      "gamma                       0\n",
      "theta                       0\n",
      "vega                        0\n",
      "rho                         0\n",
      "open_interest               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenating data to form a combined dataframe for put options\n",
    "df_call = pd.concat([\n",
    "    df1[(df1['option_type'] == 'C') & (df1['root'] == 'SPX')],\n",
    "    df2[(df2['option_type'] == 'C') & (df2['root'] == 'SPX')],\n",
    "    df3[(df3['option_type'] == 'C') & (df3['root'] == 'SPX')]\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"Null Values:\")\n",
    "print(df_call.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values:\n",
      "underlying_symbol           0\n",
      "quote_datetime              0\n",
      "root                        0\n",
      "expiration                  0\n",
      "strike                      0\n",
      "option_type                 0\n",
      "open                        0\n",
      "high                        0\n",
      "low                         0\n",
      "close                       0\n",
      "trade_volume                0\n",
      "bid_size                    0\n",
      "bid                         0\n",
      "ask_size                    0\n",
      "ask                         0\n",
      "underlying_bid              0\n",
      "underlying_ask              0\n",
      "implied_underlying_price    0\n",
      "active_underlying_price     0\n",
      "implied_volatility          0\n",
      "delta                       0\n",
      "gamma                       0\n",
      "theta                       0\n",
      "vega                        0\n",
      "rho                         0\n",
      "open_interest               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_put = pd.concat([\n",
    "    df1[(df1['option_type'] == 'P') & (df1['root'] == 'SPX')],\n",
    "    df2[(df2['option_type'] == 'P') & (df2['root'] == 'SPX')],\n",
    "    df3[(df3['option_type'] == 'P') & (df3['root'] == 'SPX')]\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"Null Values:\")\n",
    "print(df_put.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82943 entries, 0 to 82942\n",
      "Data columns (total 26 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   underlying_symbol         82943 non-null  object \n",
      " 1   quote_datetime            82943 non-null  object \n",
      " 2   root                      82943 non-null  object \n",
      " 3   expiration                82943 non-null  object \n",
      " 4   strike                    82943 non-null  float64\n",
      " 5   option_type               82943 non-null  object \n",
      " 6   open                      82943 non-null  float64\n",
      " 7   high                      82943 non-null  float64\n",
      " 8   low                       82943 non-null  float64\n",
      " 9   close                     82943 non-null  float64\n",
      " 10  trade_volume              82943 non-null  int64  \n",
      " 11  bid_size                  82943 non-null  int64  \n",
      " 12  bid                       82943 non-null  float64\n",
      " 13  ask_size                  82943 non-null  int64  \n",
      " 14  ask                       82943 non-null  float64\n",
      " 15  underlying_bid            82943 non-null  float64\n",
      " 16  underlying_ask            82943 non-null  float64\n",
      " 17  implied_underlying_price  82943 non-null  float64\n",
      " 18  active_underlying_price   82943 non-null  float64\n",
      " 19  implied_volatility        82943 non-null  float64\n",
      " 20  delta                     82943 non-null  float64\n",
      " 21  gamma                     82943 non-null  float64\n",
      " 22  theta                     82943 non-null  float64\n",
      " 23  vega                      82943 non-null  float64\n",
      " 24  rho                       82943 non-null  float64\n",
      " 25  open_interest             82943 non-null  int64  \n",
      "dtypes: float64(17), int64(4), object(5)\n",
      "memory usage: 16.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_put.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column time_to_expiration\n",
    "\n",
    "df_call['expiration'] = pd.to_datetime(df_call['expiration'])\n",
    "df_call['quote_datetime'] = pd.to_datetime(df_call['quote_datetime'])\n",
    "\n",
    "# Calculate time-to-expiration as the difference in days\n",
    "df_call['time_to_expiration'] = (df_call['expiration'] - df_call['quote_datetime']).dt.days\n",
    "\n",
    "# Repeat for df_put if needed\n",
    "df_put['expiration'] = pd.to_datetime(df_put['expiration'])\n",
    "df_put['quote_datetime'] = pd.to_datetime(df_put['quote_datetime'])\n",
    "df_put['time_to_expiration'] = (df_put['expiration'] - df_put['quote_datetime']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column bid_ask_spread\n",
    "df_call['bid_ask_spread'] = df_call['underlying_ask'] - df_call['underlying_bid']\n",
    "df_put['bid_ask_spread'] = df_put['underlying_ask'] - df_put['underlying_bid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns\n",
    "# root, underlying_symbol, implied_underlying_price, quote_datetime, expiration, bid_size, ask_size, underlying_bid, underlying_ask, open, high, low\n",
    "columns_to_drop = ['root', 'underlying_symbol', 'implied_underlying_price', 'quote_datetime', \n",
    "                   'expiration', 'open', 'high', 'low', 'bid_size', 'ask_size', \n",
    "                   'underlying_bid', 'underlying_ask']\n",
    "\n",
    "df_call = df_call.drop(columns=columns_to_drop, axis=1)\n",
    "df_put = df_put.drop(columns=columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after dropping: 4542\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where the 'close' column has a value of 0\n",
    "df_call = df_call[df_call['close'] != 0]\n",
    "\n",
    "# Verify the changes\n",
    "print(f\"Remaining rows after dropping: {len(df_call)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Step 1: Fit a scaler to the original 'close' column\n",
    "target_scaler = StandardScaler()\n",
    "target_scaler.fit(df_call[['close']])\n",
    "\n",
    "# Separating the numerical columns for scaling\n",
    "numerical_columns = ['strike', 'trade_volume', 'active_underlying_price', \n",
    "                     'implied_volatility', 'delta', 'gamma', 'theta', \n",
    "                     'vega', 'rho', 'open_interest', 'time_to_expiration', 'bid_ask_spread']\n",
    "\n",
    "# Initialize the StandardScaler for features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the numerical columns\n",
    "df_call[numerical_columns] = scaler.fit_transform(df_call[numerical_columns])\n",
    "\n",
    "# Optionally, encode the categorical 'option_type'\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_option_type = encoder.fit_transform(df_call[['option_type']])\n",
    "\n",
    "# Convert the encoded categorical feature to a DataFrame and merge it back\n",
    "encoded_df = pd.DataFrame(encoded_option_type, columns=encoder.get_feature_names_out(['option_type']))\n",
    "df_call = df_call.drop(['option_type'], axis=1)  # Drop the original 'option_type' column\n",
    "df_call = pd.concat([df_call.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling for df_put\n",
    "\n",
    "# Separating the numerical columns for scaling\n",
    "numerical_columns = ['strike', 'close', 'trade_volume', 'active_underlying_price', \n",
    "                     'implied_volatility', 'delta', 'gamma', 'theta', \n",
    "                     'vega', 'rho', 'open_interest', 'time_to_expiration', 'bid_ask_spread']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the numerical columns\n",
    "df_put[numerical_columns] = scaler.fit_transform(df_put[numerical_columns])\n",
    "\n",
    "# Optionally, encode the categorical 'option_type' if needed\n",
    "# Example using OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Updated argument name\n",
    "encoded_option_type = encoder.fit_transform(df_put[['option_type']])\n",
    "\n",
    "# Convert the encoded categorical feature to a DataFrame and merge it back\n",
    "encoded_df = pd.DataFrame(encoded_option_type, columns=encoder.get_feature_names_out(['option_type']))\n",
    "df_put = df_put.drop(['option_type'], axis=1)  # Drop the original 'option_type' column\n",
    "df_put = pd.concat([df_put.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining the ANN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input Layer\n",
    "    - 15 neurons (one for each input feature)\n",
    "2. Hidden Layer\n",
    "    - 2 hidden layers\n",
    "        - First Layer (30 neurons)\n",
    "        - Second Layer (15 neurons)\n",
    "3. Output Layer\n",
    "    - 1 neuron: the predicted price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joelsng/Library/Python/3.12/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/joelsng/Library/Python/3.12/lib/python/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_28 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_29 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with Leaky ReLU activation\n",
    "# Specify alpha for Leaky ReLU (default is usually 0.01)\n",
    "model.add(Dense(units=30, input_shape=(15,)))  # 30 neurons in the first hidden layer\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Second hidden layer with Leaky ReLU activation\n",
    "model.add(Dense(units=15))  # 15 neurons in the second hidden layer\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Output layer with 1 neuron to predict the option price (no activation function for regression)\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model with a suitable optimizer and loss function for regression\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 80397.7422 - val_loss: 723.2510\n",
      "Epoch 2/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 25428.5742 - val_loss: 676.9440\n",
      "Epoch 3/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - loss: 12056.9893 - val_loss: 673.0979\n",
      "Epoch 4/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - loss: 12151.4531 - val_loss: 670.0768\n",
      "Epoch 5/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 37564.3242 - val_loss: 666.6688\n",
      "Epoch 6/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 6925.9038 - val_loss: 664.7128\n",
      "Epoch 7/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - loss: 3964.6404 - val_loss: 657.6146\n",
      "Epoch 8/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 20799.7363 - val_loss: 636.8292\n",
      "Epoch 9/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 11186.8672 - val_loss: 615.2836\n",
      "Epoch 10/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - loss: 17594.7363 - val_loss: 613.8530\n",
      "Epoch 11/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 6128.9629 - val_loss: 590.7070\n",
      "Epoch 12/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - loss: 20951.8691 - val_loss: 578.5147\n",
      "Epoch 13/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 11382.6240 - val_loss: 574.8010\n",
      "Epoch 14/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 5908.6343 - val_loss: 562.3018\n",
      "Epoch 15/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 12856.6396 - val_loss: 523.7259\n",
      "Epoch 16/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 16240.6182 - val_loss: 478.9297\n",
      "Epoch 17/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 33345.5312 - val_loss: 419.0912\n",
      "Epoch 18/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 8170.4707 - val_loss: 376.2258\n",
      "Epoch 19/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 17406.4629 - val_loss: 346.5324\n",
      "Epoch 20/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 6449.2080 - val_loss: 314.6404\n",
      "Epoch 21/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1607.2218 - val_loss: 301.8694\n",
      "Epoch 22/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 12353.5059 - val_loss: 319.1927\n",
      "Epoch 23/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 18340.8652 - val_loss: 263.4936\n",
      "Epoch 24/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 8857.6436 - val_loss: 272.3687\n",
      "Epoch 25/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 18808.9922 - val_loss: 306.8272\n",
      "Epoch 26/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 25866.1094 - val_loss: 304.9668\n",
      "Epoch 27/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 19743.6934 - val_loss: 352.2956\n",
      "Epoch 28/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 2859.7998 - val_loss: 350.8696\n",
      "Epoch 29/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - loss: 15927.3330 - val_loss: 424.1935\n",
      "Epoch 30/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 15039.2979 - val_loss: 507.7217\n",
      "Epoch 31/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 9849.9746 - val_loss: 565.9929\n",
      "Epoch 32/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 6134.7974 - val_loss: 621.8011\n",
      "Epoch 33/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 7823.4590 - val_loss: 637.8884\n",
      "Epoch 34/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 17441.3262 - val_loss: 722.3087\n",
      "Epoch 35/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 4074.7756 - val_loss: 670.3619\n",
      "Epoch 36/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 25686.5527 - val_loss: 707.8727\n",
      "Epoch 37/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 17584.3848 - val_loss: 806.9009\n",
      "Epoch 38/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - loss: 7168.2930 - val_loss: 779.9255\n",
      "Epoch 39/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 17644.7949 - val_loss: 764.6279\n",
      "Epoch 40/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - loss: 9634.5547 - val_loss: 799.7727\n",
      "Epoch 41/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 5413.0864 - val_loss: 770.4539\n",
      "Epoch 42/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 856.4786 - val_loss: 721.9110\n",
      "Epoch 43/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 11512.5498 - val_loss: 777.7098\n",
      "Epoch 44/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 10180.8799 - val_loss: 749.0112\n",
      "Epoch 45/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 2193.8047 - val_loss: 685.1553\n",
      "Epoch 46/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 20912.7500 - val_loss: 1019.2593\n",
      "Epoch 47/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 2706.3152 - val_loss: 835.5514\n",
      "Epoch 48/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1341.2115 - val_loss: 732.6652\n",
      "Epoch 49/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - loss: 6580.3149 - val_loss: 791.3832\n",
      "Epoch 50/50\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 13178.5088 - val_loss: 781.2017\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252us/step - loss: 374.6713\n",
      "Test Loss: 1462.7845458984375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_call.drop(columns=['close'])  # Assuming 'close' is the target column you want to predict\n",
    "y = df_call['close']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the datasets to numpy arrays for compatibility with TensorFlow/Keras\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training loss and validation loss over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step\n",
      "Mean Squared Error: 1462.7846229316972\n",
      "Mean Absolute Error: 7.792713731258485\n",
      "Root Mean Squared Error: 38.246367447532805\n",
      "R-squared: 0.9906341713809085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled Mean Squared Error: 221182656.24703324\n",
      "Unscaled Mean Absolute Error: 3030.2190442523083\n",
      "Unscaled Root Mean Squared Error: 14872.21087286733\n",
      "Unscaled R-squared: 0.9906341718993888\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Unscale the predictions and actual target values\n",
    "y_pred_unscaled = target_scaler.inverse_transform(y_pred)  # Inverse transform predictions\n",
    "y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))  # Inverse transform actual values\n",
    "\n",
    "# Step 7: Calculate evaluation metrics on unscaled values\n",
    "mse_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)\n",
    "mae_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)\n",
    "rmse_unscaled = np.sqrt(mse_unscaled)\n",
    "r2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)\n",
    "\n",
    "print(f\"Unscaled Mean Squared Error: {mse_unscaled}\")\n",
    "print(f\"Unscaled Mean Absolute Error: {mae_unscaled}\")\n",
    "print(f\"Unscaled Root Mean Squared Error: {rmse_unscaled}\")\n",
    "print(f\"Unscaled R-squared: {r2_unscaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters to learn\n",
    "1. Number of hidden layers\n",
    "2. Number of neurons in each layer\n",
    "3. Learning rate\n",
    "4. Batch size\n",
    "5. Activation Functions\n",
    "6. Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "def build_model(optimizer='adam', learning_rate=0.001, num_neurons=30, num_layers=1, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=num_neurons, input_shape=(15,)))  # Input layer + First hidden layer\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Adding more hidden layers based on num_layers parameter\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units=num_neurons))\n",
    "        model.add(LeakyReLU(alpha=0.01))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(rate=dropout_rate))  # Add dropout if dropout_rate is provided\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compile the model with the specified optimizer and learning rate\n",
    "    opt = optimizer if isinstance(optimizer, str) else optimizer(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "keras_model = KerasRegressor(\n",
    "    build_fn=build_model,\n",
    "    optimizer='adam',\n",
    "    learning_rate=0.001,\n",
    "    num_neurons=30,\n",
    "    num_layers=1,\n",
    "    dropout_rate=0.0,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_neurons': [20, 30, 50],  # Number of neurons in each layer\n",
    "    'num_layers': [1, 2, 3],  # Number of hidden layers\n",
    "    'learning_rate': [0.001, 0.01, 0.1],  # Learning rates to try\n",
    "    'optimizer': ['adam', 'rmsprop'],  # Different optimizers to try\n",
    "    'batch_size': [32, 64, 128],  # Different batch sizes\n",
    "    'dropout_rate': [0.0, 0.2, 0.3, 0.5],  # Dropout rate to prevent overfitting\n",
    "    'epochs': [50, 100]  # Number of epochs\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=keras_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Best Score: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with Leaky ReLU activation\n",
    "# Specify alpha for Leaky ReLU (default is usually 0.01)\n",
    "model.add(Dense(units=20, input_shape=(15,)))  # 20 neurons in the first hidden layer (as per best parameters)\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dropout(0.2))  # Add dropout with a rate of 0.2\n",
    "\n",
    "# Second hidden layer with Leaky ReLU activation\n",
    "model.add(Dense(units=20))  # 20 neurons in the second hidden layer (as per best parameters)\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dropout(0.2))  # Add dropout with a rate of 0.2\n",
    "\n",
    "# Output layer with 1 neuron to predict the option price (no activation function for regression)\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Create an Adam optimizer with the best-found learning rate\n",
    "optimizer = Adam(learning_rate=0.001)  # Setting learning rate as per best parameters\n",
    "\n",
    "# Compile the model with the specified optimizer and loss function\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_call.drop(columns=['close'])  # Assuming 'close' is the target column you want to predict\n",
    "y = df_call['close']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the datasets to numpy arrays for compatibility with TensorFlow/Keras\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you scaled your target variable 'close' during preprocessing\n",
    "\n",
    "# Step 1: Fit the scaler on the original 'close' column\n",
    "target_scaler = StandardScaler()\n",
    "target_scaler.fit(df_call[['close']])\n",
    "\n",
    "# Step 2: Inverse transform the predictions and the actual test values\n",
    "y_pred_unscaled = target_scaler.inverse_transform(y_pred)\n",
    "y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Step 3: Calculate evaluation metrics on unscaled values\n",
    "mse_unscaled = mean_squared_error(y_test_unscaled, y_pred_unscaled)\n",
    "mae_unscaled = mean_absolute_error(y_test_unscaled, y_pred_unscaled)\n",
    "rmse_unscaled = np.sqrt(mse_unscaled)\n",
    "r2_unscaled = r2_score(y_test_unscaled, y_pred_unscaled)\n",
    "\n",
    "print(f\"Unscaled Mean Squared Error: {mse_unscaled}\")\n",
    "print(f\"Unscaled Mean Absolute Error: {mae_unscaled}\")\n",
    "print(f\"Unscaled Root Mean Squared Error: {rmse_unscaled}\")\n",
    "print(f\"Unscaled R-squared: {r2_unscaled}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
